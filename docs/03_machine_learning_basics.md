# 3. 머신러닝 기초

## 🤖 머신러닝이란?

**머신러닝(Machine Learning)**은 컴퓨터가 데이터로부터 스스로 학습하여 패턴을 찾아내는 기술입니다.

### 일상생활의 예시

#### 1. 스팸 메일 필터
```
데이터:     이메일 1000개 (스팸 500개, 정상 500개)
학습:       "무료", "당첨" 같은 단어가 스팸에 많음을 발견
결과:       새 이메일이 스팸인지 자동 판단!
```

#### 2. 얼굴 인식
```
데이터:     사람 얼굴 사진 10,000장
학습:       눈, 코, 입의 위치와 모양 패턴 학습
결과:       사진 속 사람이 누구인지 자동 인식!
```

#### 3. 외계행성 탐지 (우리의 경우!)
```
데이터:     광도 곡선 10,000개 (행성 1,000개, 비행성 9,000개)
학습:       행성 신호의 특징 패턴 학습
결과:       새 광도 곡선이 행성인지 자동 판단!
```

## 🎯 분류 (Classification)란?

**분류**는 데이터를 여러 카테고리(클래스) 중 하나로 나누는 작업입니다.

### 이진 분류 (Binary Classification)

우리의 경우: **2개의 클래스**

```python
클래스 0: 행성 아님 (Non-Planet)  ❌
클래스 1: 행성 맞음 (Planet)      ✅

목표: 광도 곡선 → 0 또는 1로 분류
```

### 분류의 원리

```
[입력]                [학습된 모델]           [출력]
광도 곡선     →     머신러닝 분류기    →    행성? (0 or 1)
 ╲___╱                   🤖                  확률: 95%
```

## 🧠 머신러닝의 종류

### 1. 지도 학습 (Supervised Learning) ⭐ 우리가 사용!

**정답(레이블)이 있는 데이터**로 학습합니다.

```python
# 학습 데이터
데이터 1: 광도곡선A → 레이블: 행성 (1)     ✓
데이터 2: 광도곡선B → 레이블: 비행성 (0)   ✓
데이터 3: 광도곡선C → 레이블: 행성 (1)     ✓
...

# 새 데이터 예측
데이터 X: 광도곡선X → 예측: ???

모델: "데이터 X는 광도곡선A와 비슷하네요!
       행성일 확률 92%입니다!" ✓
```

### 2. 비지도 학습 (Unsupervised Learning)

**정답 없이** 데이터의 패턴을 찾습니다.

```python
# 클러스터링 예시
데이터를 자동으로 그룹화:
그룹 A: 비슷한 광도 곡선들 [ooo]
그룹 B: 다른 패턴의 곡선들 [xxx]
그룹 C: 또 다른 패턴 [+++]
```

### 3. 강화 학습 (Reinforcement Learning)

**보상**을 통해 학습합니다. (예: 게임 AI)

## 📚 고전적 머신러닝 vs 딥러닝

### 고전적 머신러닝 (우리가 사용!)

```
[원시 데이터] → [특징 추출] → [모델 학습] → [예측]
   광도곡선      789개 특징      GBT 모델      행성?
```

**특징**: 사람이 직접 특징(feature)을 추출해야 함

### 딥러닝 (Deep Learning)

```
[원시 데이터] → [신경망 (자동 특징 추출 + 학습)] → [예측]
   광도곡선           CNN/RNN 등                   행성?
```

**특징**: 특징을 자동으로 학습함

### 비교표

| 구분 | 고전적 ML | 딥러닝 |
|------|----------|--------|
| **특징 추출** | 수동 (tsfresh) | 자동 |
| **학습 시간** | 빠름 (2-5분) | 느림 (수시간) |
| **필요 데이터** | 적음 | 많음 |
| **하드웨어** | CPU 충분 | GPU 필요 |
| **해석 가능성** | 높음 (어떤 특징이 중요한지 알 수 있음) | 낮음 (블랙박스) |
| **성능** | 좋음 | 매우 좋음 |

### 왜 고전적 머신러닝을 선택했나요?

1. ✅ **효율성**: 빠르고 가벼움
2. ✅ **해석 가능**: 어떤 특징이 중요한지 알 수 있음
3. ✅ **접근성**: 일반 컴퓨터로 실행 가능
4. ✅ **성능**: 딥러닝과 비슷한 결과 달성

## 🌲 결정 트리 (Decision Tree)

우리가 사용하는 **Gradient Boosted Trees**의 기본 단위입니다.

### 결정 트리의 원리

```
                  [특징1: 밝기 감소 > 0.5%?]
                    /              \
                  Yes              No
                  /                  \
      [특징2: 주기 > 2일?]         [비행성] ❌
         /           \
       Yes           No
       /               \
   [행성] ✅        [특징3: S/N > 10?]
                      /          \
                    Yes          No
                    /              \
                [행성] ✅      [비행성] ❌
```

**장점**:
- 이해하기 쉬움
- 빠른 예측
- 비선형 패턴 포착 가능

**단점**:
- 단독으로는 성능이 제한적
- 과적합 (Overfitting) 위험

**해결책**: 여러 트리를 결합! → Gradient Boosted Trees

## 🚀 Gradient Boosted Trees (GBT)

여러 개의 결정 트리를 **순차적으로** 학습하여 성능을 향상시킵니다.

### 작동 원리

```
단계 1: 첫 번째 트리 학습
        정확도: 70%

단계 2: 두 번째 트리가 첫 번째 트리의 실수를 보완
        정확도: 80%

단계 3: 세 번째 트리가 남은 실수를 보완
        정확도: 90%

...

최종: 100개 트리의 결합
      정확도: 96%! ✓
```

### Boosting의 개념

```
[약한 학습기] + [약한 학습기] + ... = [강한 학습기]
   트리 1    +     트리 2    + ... =   최종 모델
   (70%)    +     (+10%)    + ... =     (96%)
```

### LightGBM

우리가 사용하는 GBT 구현체입니다.

```python
import lightgbm as lgb

# 모델 생성
model = lgb.LGBMClassifier(
    n_estimators=100,      # 트리 100개
    max_depth=5,           # 트리 깊이
    learning_rate=0.1      # 학습 속도
)

# 학습
model.fit(X_train, y_train)

# 예측
predictions = model.predict(X_test)
```

**장점**:
- 빠른 학습 속도
- 높은 정확도
- 메모리 효율적

## 📊 모델 학습 과정

### 1. 데이터 준비

```python
전체 데이터:  10,000개 광도 곡선
    ↓
학습 세트:    8,000개 (80%)  ← 모델 학습
검증 세트:    1,000개 (10%)  ← 하이퍼파라미터 조정
테스트 세트:  1,000개 (10%)  ← 최종 성능 평가
```

### 2. 특징(Feature)과 레이블(Label)

```python
# 특징 (X): 모델의 입력
X = [
    [특징1, 특징2, 특징3, ..., 특징789],  # 광도곡선 1
    [특징1, 특징2, 특징3, ..., 특징789],  # 광도곡선 2
    ...
]

# 레이블 (y): 정답
y = [1, 0, 1, 1, 0, ...]  # 1=행성, 0=비행성
```

### 3. 학습

```python
for epoch in range(100):  # 100번 반복
    1. 예측 만들기
    2. 실제 정답과 비교
    3. 오차 계산
    4. 모델 파라미터 업데이트
```

### 4. 예측

```python
# 새로운 광도 곡선
new_curve = [특징1, 특징2, ..., 특징789]

# 예측
probability = model.predict_proba(new_curve)
# 출력: [0.05, 0.95]  ← [비행성 확률, 행성 확률]

if probability[1] > 0.5:
    print("행성입니다! ✓")
else:
    print("행성이 아닙니다.")
```

## 🎓 교차 검증 (Cross-Validation)

데이터를 효율적으로 사용하는 방법입니다.

### 10-Fold Cross Validation

```python
전체 학습 데이터를 10개로 분할:

┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐
│  1  │  2  │  3  │  4  │  5  │  6  │  7  │  8  │  9  │ 10  │
└─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘

Round 1: [검증] 학습  학습  학습  학습  학습  학습  학습  학습  학습
Round 2:  학습 [검증] 학습  학습  학습  학습  학습  학습  학습  학습
Round 3:  학습  학습 [검증] 학습  학습  학습  학습  학습  학습  학습
...
Round 10: 학습  학습  학습  학습  학습  학습  학습  학습  학습 [검증]

최종 성능 = 10번의 평균
```

**장점**:
- 모든 데이터가 학습과 검증에 사용됨
- 더 신뢰할 수 있는 성능 평가
- 과적합 방지

## 🔧 하이퍼파라미터 (Hyperparameters)

모델의 **설정값**입니다.

### 주요 하이퍼파라미터

```python
# GBT 하이퍼파라미터
n_estimators = 100      # 트리 개수 (많을수록 강력하지만 느림)
max_depth = 5           # 트리 깊이 (깊을수록 복잡한 패턴 학습)
learning_rate = 0.1     # 학습 속도 (낮을수록 안정적)
min_child_samples = 20  # 리프 노드의 최소 샘플 수

# 결정 임계값
threshold = 0.5         # 이 값 이상이면 "행성"으로 분류
```

### 하이퍼파라미터 최적화

```python
# 다양한 조합 시도
for n_trees in [50, 100, 200]:
    for depth in [3, 5, 7]:
        for lr in [0.01, 0.1, 0.3]:
            model = train(n_trees, depth, lr)
            score = evaluate(model)
            if score > best_score:
                best_params = (n_trees, depth, lr)
```

## 📝 요약

- **머신러닝**: 데이터로부터 자동으로 패턴을 학습
- **분류**: 데이터를 카테고리로 나누기
- **지도 학습**: 정답이 있는 데이터로 학습 (우리가 사용)
- **GBT**: 여러 결정 트리를 순차적으로 결합
- **교차 검증**: 데이터를 효율적으로 사용하는 평가 방법
- **고전 ML vs 딥러닝**: 우리는 효율성을 위해 고전 ML 선택

## 🤔 퀴즈로 확인하기

1. 머신러닝이란 무엇인가요?
   <details>
   <summary>답 보기</summary>
   컴퓨터가 데이터로부터 스스로 학습하여 패턴을 찾아내는 기술
   </details>

2. 지도 학습의 특징은?
   <details>
   <summary>답 보기</summary>
   정답(레이블)이 있는 데이터로 학습하는 방법
   </details>

3. GBT는 어떻게 작동하나요?
   <details>
   <summary>답 보기</summary>
   여러 개의 결정 트리를 순차적으로 학습하여 이전 트리의 실수를 보완
   </details>

4. 왜 고전적 머신러닝을 선택했나요?
   <details>
   <summary>답 보기</summary>
   빠르고, 해석 가능하며, 일반 컴퓨터로 실행 가능하면서도 좋은 성능을 냄
   </details>

## 🚀 다음 단계

머신러닝의 기초를 배웠습니다!

다음은 우리 **연구의 전체 방법론**을 살펴보겠습니다.

👉 **[다음: 연구 방법론 개요](04_methodology.md)**

---

**도움이 필요하신가요?**
- [← 이전: 트랜짓 방법 이해하기](02_transit_method.md)
- [용어 사전](09_glossary.md)에서 모르는 용어를 찾아보세요
