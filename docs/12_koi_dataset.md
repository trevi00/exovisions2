# 12. KOI ë°ì´í„°ì…‹ (Kepler Object of Interest)

## ğŸŒŒ KOI ë°ì´í„°ì…‹ì´ë€?

**KOI (Kepler Object of Interest)**ëŠ” NASAì˜ ì¼€í”ŒëŸ¬ ìš°ì£¼ ë§ì›ê²½ì´ ìˆ˜ì§‘í•œ ì™¸ê³„í–‰ì„± í›„ë³´ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.

### ì—­ì‚¬

```
2009ë…„: ì¼€í”ŒëŸ¬ ë§ì›ê²½ ë°œì‚¬
          â†“
4ë…„ê°„ 20ë§Œ ê°œ ì´ìƒì˜ ë³„ ê´€ì¸¡
          â†“
íŠ¸ëœì§“ ë°©ë²•ìœ¼ë¡œ í–‰ì„± í›„ë³´ ë°œê²¬
          â†“
KOI ë°ì´í„°ì…‹ ìƒì„±
```

**KOIì˜ íŠ¹ì§•**:
- NASA Exoplanet Science Institute (NExScI) ê°œë°œ
- ê³µê°œ ë°ì´í„°ì…‹ (ëˆ„êµ¬ë‚˜ ë¬´ë£Œ ì‚¬ìš©)
- í™•ì¸ëœ ì™¸ê³„í–‰ì„± + í›„ë³´ + ì˜¤íƒ(False Positive) í¬í•¨

## ğŸ“Š ë°ì´í„°ì…‹ êµ¬ì¡°

### ê¸°ë³¸ ì •ë³´

```
ì›ë³¸ ë°ì´í„°:
- í–‰(Rows): 9,654ê°œ
- ì—´(Columns): 50ê°œ
- íŒŒì¼ëª…: cumulative.csv
- ë‹¤ìš´ë¡œë“œ: NASA Exoplanet Archive
```

### ë°ì´í„° êµ¬ì„±

```
KOI ë°ì´í„°ì…‹ ë‚´ìš©:

1. ë³„ íŠ¹ì„± (Stellar Parameters)
   - ìœ„ì¹˜ (Position)
   - ë°ê¸° (Magnitude)
   - ì˜¨ë„ (Temperature)

2. í–‰ì„± íŠ¹ì„± (Exoplanet Parameters)
   - ì§ˆëŸ‰ (Mass)
   - ê¶¤ë„ ì •ë³´ (Orbital Information)
   - ì£¼ê¸° (Period)

3. ê´€ì¸¡ ë°ì´í„°
   - ê´‘ë„ ê³¡ì„  (Light Curve)
   - ì‹œê°„ì— ë”°ë¥¸ ë°ê¸° ë³€í™”

4. ë¶„ë¥˜ (Classification)
   - CONFIRMED: í™•ì¸ëœ ì™¸ê³„í–‰ì„±
   - CANDIDATE: ì™¸ê³„í–‰ì„± í›„ë³´
   - FALSE POSITIVE: ì˜¤íƒ
```

## ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ê³¼ì •

### 1ë‹¨ê³„: ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°

```python
# ì œê±°ëœ 6ê°œ ì»¬ëŸ¼

ì œê±° ì´ìœ : ì˜ˆì¸¡ì— ê¸°ì—¬í•˜ì§€ ì•ŠëŠ” ì‹ë³„ì

1. rowid
   - ë‹¨ìˆœ í–‰ ë²ˆí˜¸
   - Primary Key

2. kepid
   - ê³ ìœ  ëœë¤ ë²ˆí˜¸
   - í–‰ì„± ì‹ë³„ì

3. kepoi_name
   - ë‘ ë²ˆì§¸ ê³ ìœ  ë²ˆí˜¸
   - í–‰ì„± ì‹ë³„ì

4. kepler_name
   - í…ìŠ¤íŠ¸ í˜•ì‹ í–‰ì„± ì´ë¦„

5. koi_pdisposition
   - koi_dispositionê³¼ ì¤‘ë³µ
   - í˜¼ë™ ë°©ì§€ë¥¼ ìœ„í•´ ì œê±°

6. koi_score
   - 0ê³¼ 1 ì‚¬ì´ ì‹ ë¢°ë„ ê°’
   - ì˜ˆì¸¡ì— ê°„ì„­ ê°€ëŠ¥ì„±
```

### ì¶”ê°€ ì œê±°

```python
# ì™„ì „íˆ ë¹„ì–´ìˆëŠ” ì»¬ëŸ¼
- koi_teq_err1
- koi_teq_err2

# ê²°ê³¼
ì›ë³¸: 50 ì»¬ëŸ¼ â†’ ì²˜ë¦¬ í›„: 43 ì»¬ëŸ¼
```

### 2ë‹¨ê³„: íƒ€ê²Ÿ ì»¬ëŸ¼ ì •ë¦¬

```python
# ì›ë³¸ íƒ€ê²Ÿ ì»¬ëŸ¼ (koi_disposition)
ê°’: 'CONFIRMED', 'CANDIDATE', 'FALSE POSITIVE'

# ë‹¨ê³„ 1: FALSE POSITIVE ì œê±°
ì´ìœ : í™•ì¸ëœ í–‰ì„±ê³¼ í›„ë³´ë§Œ í•„ìš”

# ë‹¨ê³„ 2: ì´ì§„ ë³€í™˜
'CONFIRMED' â†’ 0 (í™•ì¸ëœ ì™¸ê³„í–‰ì„±)
'CANDIDATE' â†’ 1 (ì™¸ê³„í–‰ì„± í›„ë³´)
```

**ì™œ ì´ì§„ ë³€í™˜?**
```
ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ ë¬¸ì œ:
- 2ê°œ í´ë˜ìŠ¤ë§Œ í•„ìš”
- 0ê³¼ 1ë¡œ ë‹¨ìˆœí™”
- ì•Œê³ ë¦¬ì¦˜ í•™ìŠµ íš¨ìœ¨ í–¥ìƒ
```

### 3ë‹¨ê³„: ê²°ì¸¡ì¹˜ ì²˜ë¦¬

```python
# koi_tce_delivname ì»¬ëŸ¼
ê²°ì¸¡ì¹˜ â†’ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´

# ë²”ì£¼í˜• ë³€ìˆ˜ ë³€í™˜
ì¹´í…Œê³ ë¦¬ â†’ ë”ë¯¸ ë³€ìˆ˜ (Dummy Variables)
           ìˆ«ìë¡œ ë³€í™˜
```

### 4ë‹¨ê³„: ë°ì´í„° ë¶„í• 

```python
# X (ë…ë¦½ ë³€ìˆ˜): 43ê°œ íŠ¹ì§•
features = [
    'koi_period',        # ê¶¤ë„ ì£¼ê¸°
    'koi_time0bk',       # íŠ¸ëœì§“ ì‹œê°„
    'koi_impact',        # ì¶©ëŒ ë§¤ê°œë³€ìˆ˜
    'koi_duration',      # íŠ¸ëœì§“ ì§€ì† ì‹œê°„
    'koi_depth',         # íŠ¸ëœì§“ ê¹Šì´
    ...                  # ë‚˜ë¨¸ì§€ 38ê°œ
]

# y (ì¢…ì† ë³€ìˆ˜): 1ê°œ íƒ€ê²Ÿ
target = 'koi_disposition'  # 0 or 1
```

### 5ë‹¨ê³„: ìŠ¤ì¼€ì¼ë§

```python
from sklearn.preprocessing import StandardScaler

# StandardScaler ì ìš©
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ëª¨ë“  íŠ¹ì§•ì„ ê°™ì€ ë²”ìœ„ë¡œ ì •ê·œí™”
# í‰ê·  = 0, í‘œì¤€í¸ì°¨ = 1
```

**ìŠ¤ì¼€ì¼ë§ ì „í›„ ë¹„êµ**:
```
ìŠ¤ì¼€ì¼ë§ ì „:
koi_period: [0.5, 365, 4000, ...]  â† ë²”ìœ„ê°€ ë§¤ìš° ë„“ìŒ
koi_depth:  [10, 500, 10000, ...]  â† ë²”ìœ„ê°€ ë‹¤ë¦„

ìŠ¤ì¼€ì¼ë§ í›„:
koi_period: [-1.2, 0.3, 2.1, ...]  â† í‰ê·  0, í‘œì¤€í¸ì°¨ 1
koi_depth:  [-0.8, 1.5, 0.2, ...]  â† ê°™ì€ ë²”ìœ„
```

### 6ë‹¨ê³„: í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 

```python
from sklearn.model_selection import train_test_split

# 70% í•™ìŠµ, 30% í…ŒìŠ¤íŠ¸
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y,
    test_size=0.3,
    random_state=42,    # ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ
    stratify=y          # í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€
)

# ê²°ê³¼
í•™ìŠµ ë°ì´í„°: 3,178 í–‰ Ã— 43 ì»¬ëŸ¼
  - CONFIRMED: 1,589ê°œ
  - CANDIDATE: 1,589ê°œ

í…ŒìŠ¤íŠ¸ ë°ì´í„°: 1,362 í–‰ Ã— 43 ì»¬ëŸ¼
```

## ğŸ“ˆ ìµœì¢… ë°ì´í„°ì…‹ êµ¬ì¡°

### ì²˜ë¦¬ ì „í›„ ë¹„êµ

```
ì›ë³¸:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  9,654 í–‰ Ã— 50 ì»¬ëŸ¼          â”‚
â”‚  CONFIRMED / CANDIDATE /    â”‚
â”‚  FALSE POSITIVE             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â†“ ì „ì²˜ë¦¬

ìµœì¢…:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4,540 í–‰ Ã— 43 ì»¬ëŸ¼          â”‚
â”‚  (FALSE POSITIVE ì œê±°ë¨)     â”‚
â”‚  0 (CONFIRMED): 1,589ê°œ     â”‚
â”‚  1 (CANDIDATE): 1,589ê°œ     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â†“ ë¶„í• 

í•™ìŠµ (70%):                    í…ŒìŠ¤íŠ¸ (30%):
3,178 í–‰                       1,362 í–‰
```

## ğŸ” ì£¼ìš” íŠ¹ì§•(Features) ì„¤ëª…

### 1. ê¶¤ë„ íŠ¹ì„±

```python
# í–‰ì„±ì˜ ê¶¤ë„ ì •ë³´

koi_period         # ê¶¤ë„ ì£¼ê¸° (ì¼)
                   # ì˜ˆ: 365ì¼ = ì§€êµ¬ì™€ ë¹„ìŠ·

koi_time0bk        # ì²« íŠ¸ëœì§“ ì‹œê°„
                   # ê´€ì¸¡ ì‹œì‘ ì‹œì  ê¸°ì¤€

koi_impact         # ì¶©ëŒ ë§¤ê°œë³€ìˆ˜
                   # 0 = ë³„ ì¤‘ì‹¬ í†µê³¼
                   # 1 = ë³„ ê°€ì¥ìë¦¬
```

### 2. íŠ¸ëœì§“ íŠ¹ì„±

```python
# ê´‘ë„ ê³¡ì„ ì—ì„œ ì¶”ì¶œ

koi_duration       # íŠ¸ëœì§“ ì§€ì† ì‹œê°„ (ì‹œê°„)
                   # í–‰ì„±ì´ ë³„ì„ ê°€ë¦¬ëŠ” ì‹œê°„

koi_depth          # íŠ¸ëœì§“ ê¹Šì´ (ppm)
                   # ë°ê¸° ê°ì†ŒëŸ‰
                   # í´ìˆ˜ë¡ í° í–‰ì„±

koi_prad           # í–‰ì„± ë°˜ì§€ë¦„ (ì§€êµ¬ = 1)
                   # ì˜ˆ: 2.0 = ì§€êµ¬ì˜ 2ë°°

koi_teq            # í‰í˜• ì˜¨ë„ (K)
                   # í–‰ì„± í‘œë©´ ì˜ˆìƒ ì˜¨ë„
```

### 3. ë³„ íŠ¹ì„±

```python
# ì¤‘ì‹¬ë³„(í˜¸ìŠ¤íŠ¸ ìŠ¤íƒ€) ì •ë³´

koi_srad           # ë³„ ë°˜ì§€ë¦„ (íƒœì–‘ = 1)
koi_smass          # ë³„ ì§ˆëŸ‰ (íƒœì–‘ = 1)
koi_steff          # ë³„ ìœ íš¨ ì˜¨ë„ (K)
koi_slogg          # ë³„ í‘œë©´ ì¤‘ë ¥
```

### 4. ì‹ í˜¸ í’ˆì§ˆ

```python
# ê´€ì¸¡ ë°ì´í„° í’ˆì§ˆ

koi_model_snr      # ì‹ í˜¸ ëŒ€ ì¡ìŒ ë¹„ (S/N)
                   # í´ìˆ˜ë¡ ì‹ ë¢°ë„ ë†’ìŒ

koi_tce_plnt_num   # ë™ì¼ ë³„ ì£¼ìœ„ í–‰ì„± ë²ˆí˜¸
                   # 1 = ì²« ë²ˆì§¸ í–‰ì„±
                   # 2 = ë‘ ë²ˆì§¸ í–‰ì„±
```

## ğŸ“Š KOI vs ë‹¤ë¥¸ ë°ì´í„°ì…‹ ë¹„êµ

### ë°ì´í„°ì…‹ ë¹„êµí‘œ

| íŠ¹ì„± | KOI (Kepler) | TESS | K2 Campaign 7 |
|------|--------------|------|---------------|
| **ë§ì›ê²½** | Kepler | TESS | Kepler |
| **ê´€ì¸¡ ê¸°ê°„** | 4ë…„ | 27ì¼/ì„¹í„° | 80ì¼ |
| **ì´ ë°ì´í„°** | 9,654ê°œ | ìˆ˜ë°±ë§Œ | 7,873ê°œ |
| **í´ë˜ìŠ¤ ê· í˜•** | ê· í˜•ì¡í˜ | ì‹¬í•œ ë¶ˆê· í˜• | ê· í˜•ì¡í˜ |
| **ì‹ í˜¸ í’ˆì§ˆ** | ë†’ìŒ | ì¤‘ê°„ | ë†’ìŒ |
| **ì‚¬ìš© ëª©ì ** | ì—°êµ¬ìš© | ìµœì‹  íƒì§€ | ì‹œë®¬ë ˆì´ì…˜ |

### ì¥ë‹¨ì  ë¹„êµ

```
KOI (Kepler):
âœ… ì¥ì :
  - 4ë…„ê°„ ì¥ê¸° ê´€ì¸¡ â†’ ì—¬ëŸ¬ íŠ¸ëœì§“ í™•ì¸
  - í´ë˜ìŠ¤ ê· í˜• (50:50)
  - ë†’ì€ ì‹ í˜¸ í’ˆì§ˆ
  - 43ê°œì˜ ë‹¤ì–‘í•œ íŠ¹ì§•

âŒ ë‹¨ì :
  - ê´€ì¸¡ì´ ëë‚¨ (ë” ì´ìƒ ë°ì´í„° ì¶”ê°€ X)
  - ì œí•œëœ í•˜ëŠ˜ ì˜ì—­

TESS:
âœ… ì¥ì :
  - í˜„ì¬ ì§„í–‰ ì¤‘ (ê³„ì† ë°ì´í„° ì¶”ê°€)
  - ì „ì²œêµ¬ ê´€ì¸¡
  - ìµœì‹  ë°ì´í„°

âŒ ë‹¨ì :
  - ì§§ì€ ê´€ì¸¡ (27ì¼)
  - ì‹¬í•œ í´ë˜ìŠ¤ ë¶ˆê· í˜• (3% vs 97%)
  - ë‹¨ì¼ íŠ¸ëœì§“ë§Œ ìˆì„ ìˆ˜ ìˆìŒ

K2 Campaign 7:
âœ… ì¥ì :
  - ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° (ì™„ë²½í•œ ë¼ë²¨)
  - í´ë˜ìŠ¤ ê· í˜•
  - ì—°êµ¬ ê²€ì¦ìš©

âŒ ë‹¨ì :
  - ì‹¤ì œ ë°ì´í„°ê°€ ì•„ë‹˜
  - ì œí•œì  ì‚¬ìš©
```

## ğŸ’» ë°ì´í„° ë¡œë”© ì½”ë“œ

### ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

class KOIDataProcessor:
    """KOI ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self, filepath):
        self.filepath = filepath
        self.df = None
        self.X = None
        self.y = None
        self.scaler = StandardScaler()

    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print("1. ë°ì´í„° ë¡œë”© ì¤‘...")
        self.df = pd.read_csv(self.filepath)
        print(f"   ì›ë³¸: {self.df.shape[0]} í–‰ Ã— {self.df.shape[1]} ì»¬ëŸ¼")
        return self

    def remove_columns(self):
        """ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°"""
        print("2. ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±° ì¤‘...")

        columns_to_remove = [
            'rowid', 'kepid', 'kepoi_name',
            'kepler_name', 'koi_pdisposition',
            'koi_score', 'koi_teq_err1', 'koi_teq_err2'
        ]

        self.df = self.df.drop(columns=columns_to_remove, errors='ignore')
        print(f"   ë‚¨ì€ ì»¬ëŸ¼: {self.df.shape[1]}ê°œ")
        return self

    def filter_target(self):
        """FALSE POSITIVE ì œê±°"""
        print("3. FALSE POSITIVE ì œê±° ì¤‘...")

        before = len(self.df)
        self.df = self.df[self.df['koi_disposition'].isin(['CONFIRMED', 'CANDIDATE'])]
        after = len(self.df)

        print(f"   ì œê±°ëœ í–‰: {before - after}ê°œ")
        print(f"   ë‚¨ì€ í–‰: {after}ê°œ")
        return self

    def encode_target(self):
        """íƒ€ê²Ÿ ì»¬ëŸ¼ ì´ì§„ ì¸ì½”ë”©"""
        print("4. íƒ€ê²Ÿ ì»¬ëŸ¼ ì¸ì½”ë”© ì¤‘...")

        self.df['koi_disposition'] = self.df['koi_disposition'].map({
            'CONFIRMED': 0,
            'CANDIDATE': 1
        })

        print(f"   CONFIRMED (0): {(self.df['koi_disposition'] == 0).sum()}ê°œ")
        print(f"   CANDIDATE (1): {(self.df['koi_disposition'] == 1).sum()}ê°œ")
        return self

    def handle_missing(self):
        """ê²°ì¸¡ì¹˜ ì²˜ë¦¬"""
        print("5. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì¤‘...")

        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼: í‰ê· ìœ¼ë¡œ ëŒ€ì²´
        numeric_cols = self.df.select_dtypes(include=[np.number]).columns
        self.df[numeric_cols] = self.df[numeric_cols].fillna(
            self.df[numeric_cols].mean()
        )

        # ë²”ì£¼í˜• ì»¬ëŸ¼: ë”ë¯¸ ë³€ìˆ˜ ë³€í™˜
        categorical_cols = self.df.select_dtypes(include=['object']).columns
        categorical_cols = categorical_cols.drop('koi_disposition', errors='ignore')

        if len(categorical_cols) > 0:
            self.df = pd.get_dummies(self.df, columns=categorical_cols)

        print("   âœ“ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ")
        return self

    def split_features_target(self):
        """íŠ¹ì§•ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬"""
        print("6. íŠ¹ì§•/íƒ€ê²Ÿ ë¶„ë¦¬ ì¤‘...")

        self.y = self.df['koi_disposition']
        self.X = self.df.drop('koi_disposition', axis=1)

        print(f"   íŠ¹ì§•(X): {self.X.shape}")
        print(f"   íƒ€ê²Ÿ(y): {self.y.shape}")
        return self

    def scale_features(self):
        """íŠ¹ì§• ìŠ¤ì¼€ì¼ë§"""
        print("7. íŠ¹ì§• ìŠ¤ì¼€ì¼ë§ ì¤‘...")

        self.X = pd.DataFrame(
            self.scaler.fit_transform(self.X),
            columns=self.X.columns,
            index=self.X.index
        )

        print("   âœ“ StandardScaler ì ìš© ì™„ë£Œ")
        return self

    def split_train_test(self, test_size=0.3, random_state=42):
        """í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• """
        print("8. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í•  ì¤‘...")

        X_train, X_test, y_train, y_test = train_test_split(
            self.X, self.y,
            test_size=test_size,
            random_state=random_state,
            stratify=self.y
        )

        print(f"   í•™ìŠµ ì„¸íŠ¸: {X_train.shape}")
        print(f"   í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: {X_test.shape}")
        print("\nâœ“ ì „ì²˜ë¦¬ ì™„ë£Œ!")

        return X_train, X_test, y_train, y_test

    def process_all(self, test_size=0.3, random_state=42):
        """ì „ì²´ ì „ì²˜ë¦¬ ì‹¤í–‰"""
        return (self.load_data()
                    .remove_columns()
                    .filter_target()
                    .encode_target()
                    .handle_missing()
                    .split_features_target()
                    .scale_features()
                    .split_train_test(test_size, random_state))

# ì‚¬ìš© ì˜ˆì‹œ
processor = KOIDataProcessor('cumulative.csv')
X_train, X_test, y_train, y_test = processor.process_all()
```

## ğŸ¯ ì•™ìƒë¸” ì•Œê³ ë¦¬ì¦˜ ì ìš© ê²°ê³¼

### 5ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥

```
ë°ì´í„°: KOI ë°ì´í„°ì…‹ (4,540 í–‰)
ë°©ë²•: 10-fold êµì°¨ ê²€ì¦
í‰ê°€: Accuracy, Precision, Recall, F1 Score

ê²°ê³¼:
ëª¨ë“  ì•™ìƒë¸” ì•Œê³ ë¦¬ì¦˜ì´ 80% ì´ìƒ ë‹¬ì„±!
```

| ì•Œê³ ë¦¬ì¦˜ | Accuracy | Precision | Recall | F1 Score | ì‹œê°„(ì´ˆ) |
|---------|----------|-----------|--------|----------|---------|
| **Stacking** | **83.08%** | **83.23%** | **80.05%** | **82.84%** | 10,856 |
| Adaboost | 82.52% | 82.86% | 79.45% | 82.43% | 1,627 |
| Random Forest | 82.64% | 82.81% | 76.64% | 82.52% | 2,916 |
| Random Subspace | 81.91% | 81.98% | 78.39% | 81.78% | 1,312 |
| Extra Trees | 82.36% | 82.27% | 79.08% | 82.21% | 155 |

### ì£¼ìš” ë°œê²¬

**1. Stackingì´ ìµœê³  ì„±ëŠ¥**
```
Accuracy: 83.08%
- ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜ì˜ ì¥ì  ê²°í•©
- ë©”íƒ€-ëª¨ë¸ì´ ìµœì  ì¡°í•© í•™ìŠµ
```

**2. ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ì´ ìš°ìˆ˜**
```
í‰ê·  Accuracy: 82.50%
- 80% ì´ìƒì˜ ì¼ê´€ëœ ì„±ëŠ¥
- ì•™ìƒë¸”ì˜ ê°•ë ¥í•¨ ì…ì¦
```

**3. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì˜ ì¤‘ìš”ì„±**
```
Adaboost ì˜ˆì‹œ:
íŠœë‹ ì „: 81.37%
íŠœë‹ í›„: 82.52%
í–¥ìƒ: +1.15%
```

## ğŸ”„ êµì°¨ ê²€ì¦ (Cross-Validation)

### 10-Fold CV ì ìš©

```python
from sklearn.model_selection import StratifiedKFold

# 10ê°œë¡œ ë¶„í• 
kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

# ê° í´ë“œë§ˆë‹¤ í•™ìŠµ ë° í‰ê°€
for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train, y_train)):
    # í´ë“œë³„ ë°ì´í„° ë¶„í• 
    X_tr = X_train[train_idx]
    y_tr = y_train[train_idx]
    X_vl = X_train[val_idx]
    y_vl = y_train[val_idx]

    # ëª¨ë¸ í•™ìŠµ
    model.fit(X_tr, y_tr)

    # í‰ê°€
    score = model.score(X_vl, y_vl)
    print(f"Fold {fold + 1}: {score:.4f}")

# í‰ê·  ì ìˆ˜
print(f"í‰ê·  Accuracy: {np.mean(scores):.4f}")
```

**êµì°¨ ê²€ì¦ì˜ ì¥ì **:
```
1. ê³¼ì í•© ë°©ì§€
   - ì—¬ëŸ¬ ë²ˆ ê²€ì¦ìœ¼ë¡œ ì‹ ë¢°ë„ ë†’ì„

2. ë°ì´í„° íš¨ìœ¨ì  ì‚¬ìš©
   - ëª¨ë“  ë°ì´í„°ë¥¼ í•™ìŠµê³¼ ê²€ì¦ì— í™œìš©

3. ì¼ë°˜í™” ì„±ëŠ¥ í‰ê°€
   - ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ë ¥ ì¸¡ì •
```

## ğŸ“ ìš”ì•½

- **KOI ë°ì´í„°ì…‹**: Kepler ë§ì›ê²½ì˜ ì™¸ê³„í–‰ì„± í›„ë³´ ë°ì´í„°
- **ê·œëª¨**: 9,654 í–‰ â†’ ì „ì²˜ë¦¬ í›„ 4,540 í–‰
- **íŠ¹ì§•**: 50 ì»¬ëŸ¼ â†’ 43 ì»¬ëŸ¼ (ì˜ˆì¸¡ ê´€ë ¨)
- **ë¶„í• **: 70% í•™ìŠµ (3,178), 30% í…ŒìŠ¤íŠ¸ (1,362)
- **í´ë˜ìŠ¤**: ê· í˜•ì¡í˜ (50:50)
- **ì „ì²˜ë¦¬**: ì»¬ëŸ¼ ì œê±°, ì´ì§„ ì¸ì½”ë”©, ìŠ¤ì¼€ì¼ë§
- **ì„±ëŠ¥**: ëª¨ë“  ì•™ìƒë¸” ì•Œê³ ë¦¬ì¦˜ 80% ì´ìƒ
- **ìµœê³ **: Stacking 83.08%

## ğŸ¤” í€´ì¦ˆë¡œ í™•ì¸í•˜ê¸°

1. KOI ë°ì´í„°ì…‹ì˜ íƒ€ê²Ÿ ì»¬ëŸ¼ ê°’ì€?
   <details>
   <summary>ë‹µ ë³´ê¸°</summary>
   0 (CONFIRMED) ë˜ëŠ” 1 (CANDIDATE)
   </details>

2. ì™œ FALSE POSITIVEë¥¼ ì œê±°í–ˆë‚˜ìš”?
   <details>
   <summary>ë‹µ ë³´ê¸°</summary>
   í™•ì¸ëœ í–‰ì„±ê³¼ í›„ë³´ë§Œ í•„ìš”í•˜ê³ , ì˜¤íƒì€ ì˜ˆì¸¡ì— í˜¼ë€ì„ ì¤„ ìˆ˜ ìˆê¸° ë•Œë¬¸
   </details>

3. KOI ë°ì´í„°ì…‹ì˜ ê°€ì¥ í° ì¥ì ì€?
   <details>
   <summary>ë‹µ ë³´ê¸°</summary>
   4ë…„ ì¥ê¸° ê´€ì¸¡ìœ¼ë¡œ ë†’ì€ ì‹ í˜¸ í’ˆì§ˆê³¼ ê· í˜•ì¡íŒ í´ë˜ìŠ¤ ë¶„í¬
   </details>

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

KOI ë°ì´í„°ì…‹ì„ ì´í•´í–ˆìŠµë‹ˆë‹¤!

ë‹¤ìŒì€ **ì•™ìƒë¸” ì•Œê³ ë¦¬ì¦˜ì˜ ìƒì„¸ ê²°ê³¼**ë¥¼ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.

ğŸ‘‰ **[ë‹¤ìŒ: ì•™ìƒë¸” ê²°ê³¼ ë¶„ì„](13_ensemble_results.md)**

---

**ì°¸ê³  ìë£Œ**:
- ì›ë³¸ ë…¼ë¬¸: "Assessment of Ensemble-Based Machine Learning Algorithms for Exoplanet Identification" (Electronics, 2024)
- NASA Exoplanet Archive: https://exoplanetarchive.ipac.caltech.edu/
- Kaggle KOI Dataset: https://www.kaggle.com/datasets/nasa/kepler-exoplanet-search-results
- [â† ì´ì „: ì•™ìƒë¸” ë°©ë²•](11_ensemble_methods.md)
- [ìš©ì–´ ì‚¬ì „](09_glossary.md)
